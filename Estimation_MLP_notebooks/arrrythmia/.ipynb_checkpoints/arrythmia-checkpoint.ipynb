{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 00:20:56.629562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 00:20:57.366460: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the arrhythmia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 280)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>QRSduration</th>\n",
       "      <th>PRinterval</th>\n",
       "      <th>Q-Tinterval</th>\n",
       "      <th>Tinterval</th>\n",
       "      <th>Pinterval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>chV6_QwaveAmp</th>\n",
       "      <th>chV6_RwaveAmp</th>\n",
       "      <th>chV6_SwaveAmp</th>\n",
       "      <th>chV6_RPwaveAmp</th>\n",
       "      <th>chV6_SPwaveAmp</th>\n",
       "      <th>chV6_PwaveAmp</th>\n",
       "      <th>chV6_TwaveAmp</th>\n",
       "      <th>chV6_QRSA</th>\n",
       "      <th>chV6_QRSTA</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>382</td>\n",
       "      <td>154</td>\n",
       "      <td>117</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>361</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>176</td>\n",
       "      <td>365</td>\n",
       "      <td>194</td>\n",
       "      <td>116</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>386</td>\n",
       "      <td>218</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>364</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  height  weight  QRSduration  PRinterval  Q-Tinterval   \n",
       "0     75    0     190      80           91         193          371  \\\n",
       "1     56    1     165      64           81         174          401   \n",
       "2     54    0     172      95          138         163          386   \n",
       "3     55    0     175      94          100         202          380   \n",
       "4     75    0     190      80           88         181          360   \n",
       "..   ...  ...     ...     ...          ...         ...          ...   \n",
       "447   53    1     160      70           80         199          382   \n",
       "448   37    0     190      85          100         137          361   \n",
       "449   36    0     166      68          108         176          365   \n",
       "450   32    1     155      55           93         106          386   \n",
       "451   78    1     160      70           79         127          364   \n",
       "\n",
       "     Tinterval  Pinterval  QRS  ...  chV6_QwaveAmp  chV6_RwaveAmp   \n",
       "0          174        121  -16  ...            0.0            9.0  \\\n",
       "1          149         39   25  ...            0.0            8.5   \n",
       "2          185        102   96  ...            0.0            9.5   \n",
       "3          179        143   28  ...            0.0           12.2   \n",
       "4          177        103  -16  ...            0.0           13.1   \n",
       "..         ...        ...  ...  ...            ...            ...   \n",
       "447        154        117  -37  ...            0.0            4.3   \n",
       "448        201         73   86  ...            0.0           15.6   \n",
       "449        194        116  -85  ...            0.0           16.3   \n",
       "450        218         63   54  ...           -0.4           12.0   \n",
       "451        138         78   28  ...            0.0           10.4   \n",
       "\n",
       "     chV6_SwaveAmp  chV6_RPwaveAmp  chV6_SPwaveAmp  chV6_PwaveAmp   \n",
       "0             -0.9             0.0             0.0            0.9  \\\n",
       "1              0.0             0.0             0.0            0.2   \n",
       "2             -2.4             0.0             0.0            0.3   \n",
       "3             -2.2             0.0             0.0            0.4   \n",
       "4             -3.6             0.0             0.0           -0.1   \n",
       "..             ...             ...             ...            ...   \n",
       "447           -5.0             0.0             0.0            0.7   \n",
       "448           -1.6             0.0             0.0            0.4   \n",
       "449          -28.6             0.0             0.0            1.5   \n",
       "450           -0.7             0.0             0.0            0.5   \n",
       "451           -1.8             0.0             0.0            0.5   \n",
       "\n",
       "     chV6_TwaveAmp  chV6_QRSA  chV6_QRSTA   Y  \n",
       "0              2.9       23.3        49.4   8  \n",
       "1              2.1       20.4        38.8   6  \n",
       "2              3.4       12.3        49.0  10  \n",
       "3              2.6       34.6        61.6   1  \n",
       "4              3.9       25.4        62.8   7  \n",
       "..             ...        ...         ...  ..  \n",
       "447            0.6       -4.4        -0.5   1  \n",
       "448            2.4       38.0        62.4  10  \n",
       "449            1.0      -44.2       -33.2   2  \n",
       "450            2.4       25.0        46.6   1  \n",
       "451            1.6       21.3        32.8   1  \n",
       "\n",
       "[452 rows x 280 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./arrhythmia.csv', sep = ',')\n",
    "print (np.shape(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       8\n",
      "1       6\n",
      "2      10\n",
      "3       1\n",
      "4       7\n",
      "       ..\n",
      "447     1\n",
      "448    10\n",
      "449     2\n",
      "450     1\n",
      "451     1\n",
      "Name: Y, Length: 452, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       6\n",
       "2      10\n",
       "3       1\n",
       "4       7\n",
       "5      14\n",
       "       ..\n",
       "447     1\n",
       "448    10\n",
       "449     2\n",
       "450     1\n",
       "451     1\n",
       "Name: Y, Length: 451, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       8\n",
      "1       6\n",
      "2      10\n",
      "3       1\n",
      "4       7\n",
      "       ..\n",
      "447     1\n",
      "448    10\n",
      "449     2\n",
      "450     1\n",
      "451     1\n",
      "Name: Y, Length: 452, dtype: int64\n",
      "[ 1  2  3  4  5  6  7  8  9 10 14 15 16]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "print(y)\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 16)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75.    0.  190.  ...   2.9  23.3  49.4]\n",
      " [ 56.    1.  165.  ...   2.1  20.4  38.8]\n",
      " [ 54.    0.  172.  ...   3.4  12.3  49. ]\n",
      " ...\n",
      " [ 36.    0.  166.  ...   1.  -44.2 -33.2]\n",
      " [ 32.    1.  155.  ...   2.4  25.   46.6]\n",
      " [ 78.    1.  160.  ...   1.6  21.3  32.8]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51. ,   0. , 170. , ...,   2.6,  23.7,  47.6],\n",
       "       [ 45. ,   0. , 175. , ...,   1. ,  10.5,  17.9],\n",
       "       [ 31. ,   1. , 165. , ...,   0.9,   9.6,  14.4],\n",
       "       ...,\n",
       "       [ 35. ,   1. , 155. , ...,   0.8,  11.5,  15.5],\n",
       "       [ 34. ,   0. , 170. , ...,   2.6,  44. ,  68.4],\n",
       "       [ 49. ,   1. , 162. , ...,   0.5,  15.8,  19.8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5  9 12  5  0  0  0  2  5  0  0  0  8  0  5 10 12  0  1  1  0  3  0\n",
      "  2  2  0  0  9 12  9  1  9  0  0  2  9  0  0  0  9  0  5  0 11  9  5  0\n",
      " 12  0  1  0  0  9  0  9  0  0  0  0  9  7  0  0  9  0  0  0  9  0  2  0\n",
      " 12  0  1  1  0  9  9 12  0  0  9  0  4  0  0  9  4  0  1  0  0  1  0  2\n",
      "  0  5  0  0  3 12  9  0  4  5  0  0  5  0 10  3  1  0  0  0  9  0  0  1\n",
      "  0  0  0  4  0  0  9  0  0  2  5  1  0  0 10  0]\n"
     ]
    }
   ],
   "source": [
    "ls=np.argmax(Y_test,axis=1)\n",
    "print(ls)\n",
    "#np.savetxt('output_classes.dat',ls, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61445783 0.         0.0962963  ... 0.71666667 0.51052632 0.54191818]\n",
      " [0.54216867 0.         0.1037037  ... 0.58333333 0.4112782  0.342723  ]\n",
      " [0.37349398 1.         0.08888889 ... 0.575      0.40451128 0.31924883]\n",
      " ...\n",
      " [0.42168675 1.         0.07407407 ... 0.56666667 0.41879699 0.32662643]\n",
      " [0.40963855 0.         0.0962963  ... 0.71666667 0.66315789 0.68142186]\n",
      " [0.59036145 1.         0.08444444 ... 0.54166667 0.45112782 0.35546613]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (316, 274)\n",
      "Shape of X_test:  (136, 274)\n",
      "Shape of y_train:  (316, 16)\n",
      "Shape of y_test (136, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",Y_train.shape)\n",
    "print(\"Shape of y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from joblib import load\n",
    "# loaded_model = load('./Arrhythmia.MLP_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = MLPClassifier(beta_1=0.5553817511197982, beta_2=0.7408615040451714,\n",
    "              epsilon=0.769773517554749, hidden_layer_sizes=5,\n",
    "              learning_rate='adaptive', max_iter=150,\n",
    "              momentum=0.9205475833293032, solver='lbfgs',\n",
    "              validation_fraction=0.7720568212000914).fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=loaded_model.coefs_[0]\n",
    "b1=loaded_model.intercepts_[0]\n",
    "w2=loaded_model.coefs_[1]\n",
    "b2=loaded_model.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "lm = MLPClassifier( hidden_layer_sizes=5,solver='adam', learning_rate='adaptive', learning_rate_init=0.01,max_iter=300).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=lm.coefs_[0]\n",
    "b1=lm.intercepts_[0]\n",
    "w2=lm.coefs_[1]\n",
    "b2=lm.intercepts_[1]\n",
    "\n",
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)\n",
    "loaded_model.score(X_test,ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=274\n",
    "layer_2=5\n",
    "layer_3=16\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "\n",
    "\n",
    "sparsity_val = 0\n",
    "weight_bias_size=[ [ (8,1), (8,1) ], [ (8,1), (8,1) ] ]\n",
    "relu_size=(8,0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(QDense(layer_2, input_shape=(layer_1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(layer_3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "model.layers[0].set_weights(wb1)\n",
    "model.layers[2].set_weights(wb2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import model_save_quantized_weights\n",
    "adam = tf.keras.optimizers.Adam(\n",
    "     learning_rate=0.001\n",
    " ) \n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "callbacks= all_callbacks( outputDir = 'model_red_wine_classification_prune')\n",
    "callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "model.fit(X_train, Y_train, batch_size=1,\n",
    "        epochs=10,validation_split=0.2, verbose=1, shuffle=True,\n",
    "        callbacks = callbacks.callbacks);\n",
    "model = strip_pruning(model)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "#print(model.get_weights())\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import blackbox as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=weights[0]\n",
    "b1=weights[1]\n",
    "w2=weights[2]\n",
    "b2=weights[3]\n",
    "\n",
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bb)\n",
    "weight_size_f1=8\n",
    "bias_size_f1=8\n",
    "weight_size_f2=8\n",
    "bias_size_f2=8\n",
    "relusize_f=8\n",
    "reluint=2\n",
    "input_s=4\n",
    "layer_1=274\n",
    "layer_2=5\n",
    "layer_3=16\n",
    "\n",
    "\n",
    "accuracy, weights = bb.blackbox(wb1, wb2, relusize_f, weight_size_f1, bias_size_f1, weight_size_f2, bias_size_f2, 0, 4, reluint, layer_1, layer_2, layer_3, X_test, Y_test, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genetic algorithm to determine the relu size, weight size, bias size and sparsity\n",
    "x1: relu_size\n",
    "x2: weight_size\n",
    "x3: bias_size\n",
    "x4: sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem: max( blackbox(x1,x2,x3,x4)\n",
    "         min ( x1*x2*x3)\n",
    "       s.t\n",
    "         2 < x1,x2,x3 < 8\n",
    "         x4 belongs to [0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackbox as bb\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "import area as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self,weightsbiases1,weightsbiases2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train):\n",
    "        self.weightsbiases1=weightsbiases1\n",
    "        self.weightsbiases2=weightsbiases2\n",
    "        self.layer1=layer1\n",
    "        self.layer2=layer2\n",
    "        self.layer3=layer3\n",
    "        self.X_test=X_test\n",
    "        self.X_train=X_train\n",
    "        self.Y_test=Y_test\n",
    "        self.Y_train=Y_train\n",
    "        #x[0]: relu_size\n",
    "        #x[1]: weight size layer1\n",
    "        #x[2]: bias size layer1\n",
    "        #x[3]: weight size layer2\n",
    "        #x[4]: bias size layer2\n",
    "        #x[5]: pruning sparsity\n",
    "        #x[6]: input size\n",
    "        \n",
    "        super().__init__(n_var=7,\n",
    "                         n_obj=2,\n",
    "                         n_ieq_constr=0,\n",
    "                         xl=np.array([3,2,2,2,2,2,2]),\n",
    "                         xu=np.array([8,7,7,7,7,5,4]),\n",
    "                         vtype=int)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        accuracy, weights = bb.blackbox(self.weightsbiases1,self.weightsbiases2, x[0], x[1], x[2], x[3], x[4], x[5], x[6] ,self.layer1, self.layer2, self.layer3, self.X_test, self.Y_test, self.X_train, self.Y_train)\n",
    "        f1 = 1- accuracy\n",
    "        f2 = ar.area(weights,x[6],x[0],x[1],x[3],self.layer1,self.layer2,self.layer3)\n",
    "\n",
    "        out[\"F\"] = [f1, f2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=16\n",
    "layer2=5\n",
    "layer3=10\n",
    "problem = MyProblem(wb1,wb2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithm = NSGA2(\n",
    "    pop_size=2,\n",
    "    n_offsprings=1,\n",
    "    sampling=IntegerRandomSampling(),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.termination import get_termination\n",
    "\n",
    "termination = get_termination(\"n_gen\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymoo.optimize import minimize\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "X = res.X\n",
    "F = res.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot all the solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "pop=res.pop\n",
    "vals=pop.get(\"F\")\n",
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(vals, facecolor=\"none\", edgecolor=\"red\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the pareto solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(res.F, facecolor=\"none\", edgecolor=\"blue\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define an optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relusize_f=6\n",
    "weight_size_f1=3\n",
    "bias_size_f1=2\n",
    "weight_size_f2=5\n",
    "bias_size_f2=3\n",
    "sparsity=3.95\n",
    "input_s=4\n",
    "norm = 2**input_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relusize_f=5\n",
    "weight_size_f1=2\n",
    "bias_size_f1=2\n",
    "weight_size_f2=4\n",
    "bias_size_f2=2\n",
    "sparsity=3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=21\n",
    "layer_2=3\n",
    "layer_3=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize the input based on the selected bitwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "for i in range(0,len(X_train)):\n",
    "    X_train[i] = [round(x*norm)/norm for x in X_train[i]]\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test[i] = [round(x*norm)/norm for x in X_test[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model with the optimal solution's parameters and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "sparsity_val = float(sparsity / 10)\n",
    "weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "relu_size=(relusize_f,0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(QDense(layer_2, input_shape=(layer_1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(layer_3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "model.layers[0].set_weights(wb1)\n",
    "model.layers[2].set_weights(wb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import model_save_quantized_weights\n",
    "adam = Adam(lr=0.003)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "callbacks= all_callbacks( outputDir = 'model_red_wine_classification_prune')\n",
    "callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "model.fit(X_train, Y_train, batch_size=1,\n",
    "        epochs=5,validation_split=0.2, verbose=0, shuffle=True,\n",
    "        callbacks = callbacks.callbacks);\n",
    "model = strip_pruning(model)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "#print(model.get_weights())\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GZ\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "def aptype_to_size(ap):\n",
    "    if \"ap_int\" in ap:\n",
    "        s=ap.split('<')[1].split('>')[0]\n",
    "        i=s\n",
    "    else:\n",
    "        s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "    return (int(s),int(i))\n",
    "\n",
    "#get weights\n",
    "print(model.get_weights())\n",
    "#scale weights\n",
    "allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "#scale=[2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,_ in enumerate(model.get_weights())]\n",
    "#print(scale)\n",
    "print(allweights)\n",
    "#cast weights to integer & transpose\n",
    "allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "print(allweightsT)\n",
    "weight_list=allweightsT[0::2]\n",
    "bias_list=allweightsT[1::2]\n",
    "print(weight_list)\n",
    "print(bias_list)\n",
    "\n",
    "#set params\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "last_layer=\"linear\"\n",
    "input_size = (4,0)\n",
    "relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "\n",
    "weight_bias_size= [\n",
    "    [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "    [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "]  \n",
    "sum_relu_size=[\n",
    "    [(16,6),relu_size],\n",
    "    [(16,6),(32,6)]\n",
    "]\n",
    "print(weight_bias_size)\n",
    "print(sum_relu_size)\n",
    "\n",
    "\n",
    "f=open(\"top.v\",\"w\")\n",
    "\n",
    "import write_mlp_mergemult_ps as wv\n",
    "wv.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "f.close()\n",
    "\n",
    "f=open(\"sim.Xtest\",\"w\")\n",
    "np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "f.close()\n",
    "\n",
    "from joblib import dump\n",
    "dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=model.get_weights()\n",
    "model.set_weights(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "#print(model.get_weights())\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the network's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering as cl\n",
    "from importlib import reload\n",
    "layer1=21\n",
    "layer2=3 \n",
    "layer3=3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight clustering for the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer=0\n",
    "iterations=0\n",
    "new_accuracy=1\n",
    "accuracies=[]\n",
    "weights=[]\n",
    "while(new_accuracy > 0):\n",
    "    reload(cl)\n",
    "    new_weights, new_accuracy = cl.clustering(model,target_layer,layer1,layer2,layer3,X_test,Y_test,X_train,Y_train, weight_bias_size, relu_size);\n",
    "    iterations = iterations + 1\n",
    "    print(\"Accuracy of iteration \"+str(iterations)+\" for the target layer \"+str(target_layer)+\" is: \"+str(new_accuracy))\n",
    "    model.set_weights(new_weights)\n",
    "    accuracies.append(new_accuracy)\n",
    "    weights.append(new_weights)\n",
    "    if new_accuracy < accuracy[1]-0.03:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(accuracies)\n",
    "if max_value >= accuracy[1]-0.02:\n",
    "    print(\"here\")\n",
    "    max_index = accuracies.index(max_value)\n",
    "    model.set_weights(weights[max_index])\n",
    "else:\n",
    "    model.set_weights(w1)\n",
    "previous_weights=model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight clustering for the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer=2\n",
    "iterations=0\n",
    "new_accuracy=1\n",
    "accuracies_1=[]\n",
    "weights_1=[]\n",
    "while(new_accuracy > 0):\n",
    "    reload(cl)\n",
    "    new_weights, new_accuracy = cl.clustering(model,target_layer,layer1,layer2,layer3,X_test,Y_test,X_train,Y_train, weight_bias_size, relu_size);\n",
    "    iterations = iterations + 1\n",
    "    print(\"Accuracy of iteration \"+str(iterations)+\" for the target layer \"+str(target_layer)+\" is: \"+str(new_accuracy))\n",
    "    model.set_weights(new_weights)\n",
    "    accuracies_1.append(new_accuracy)\n",
    "    weights_1.append(new_weights)\n",
    "    if new_accuracy < accuracy[1]-0.03:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(accuracies_1)\n",
    "if max_value >= accuracy[1]-0.02:\n",
    "    print(\"here\")\n",
    "    max_index = accuracies_1.index(max_value)\n",
    "    model.set_weights(weights_1[max_index])\n",
    "else:\n",
    "    model.set_weights(previous_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GZ\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "def aptype_to_size(ap):\n",
    "    if \"ap_int\" in ap:\n",
    "        s=ap.split('<')[1].split('>')[0]\n",
    "        i=s\n",
    "    else:\n",
    "        s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "    return (int(s),int(i))\n",
    "\n",
    "#get weights\n",
    "print(model.get_weights())\n",
    "#scale weights\n",
    "allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "#scale=[2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,_ in enumerate(model.get_weights())]\n",
    "#print(scale)\n",
    "print(allweights)\n",
    "#cast weights to integer & transpose\n",
    "allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "print(allweightsT)\n",
    "weight_list=allweightsT[0::2]\n",
    "bias_list=allweightsT[1::2]\n",
    "print(weight_list)\n",
    "print(bias_list)\n",
    "\n",
    "#set params\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "last_layer=\"linear\"\n",
    "input_size = (4,0)\n",
    "relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "\n",
    "weight_bias_size= [\n",
    "    [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "    [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "]  \n",
    "sum_relu_size=[\n",
    "    [(16,6),relu_size],\n",
    "    [(16,6),(32,6)]\n",
    "]\n",
    "print(weight_bias_size)\n",
    "print(sum_relu_size)\n",
    "\n",
    "\n",
    "f=open(\"top_clustered_custom.v\",\"w\")\n",
    "\n",
    "import write_mlp_mergemult_ps as wv\n",
    "wv.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "f.close()\n",
    "\n",
    "f=open(\"sim.Xtest\",\"w\")\n",
    "np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "f.close()\n",
    "\n",
    "from joblib import dump\n",
    "dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
