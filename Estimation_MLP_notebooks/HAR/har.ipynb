{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis/2022.1/bin:' + os.environ['PATH']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82300/1605945988.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_train = pd.read_csv('./input/X_train.txt', delimiter =r'\\s+(?=-)|\\s+', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 561)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./input/X_train.txt', delimiter =r'\\s+(?=-)|\\s+', header=None)\n",
    "df_train.head()\n",
    "X_train = df_train.values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 561)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 1)\n"
     ]
    }
   ],
   "source": [
    "dfyt = pd.read_csv('./input/y_train.txt', delimiter=' ', header=None)\n",
    "dfyt = dfyt.rename(index = int,columns = {0:561})\n",
    "Y_train = dfyt.values\n",
    "Y_train -= 1\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[0 1 2 3 4 5]\n",
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "(7352, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "print(Y_train)\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "print(le.classes_)\n",
    "Y_train = to_categorical(Y_train, 6)\n",
    "print(Y_train)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82300/2884645286.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_test = pd.read_csv('./input/X_test.txt', delimiter =r'\\s+(?=-)|\\s+', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 561)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./input/X_test.txt', delimiter =r'\\s+(?=-)|\\s+', header=None)\n",
    "df_test.head()\n",
    "X_test = df_test.values\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 561)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.values\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_csv('./input/y_test.txt', delimiter=' ', header=None)\n",
    "dfytest = y_test.rename(index = int,columns = {0:561})\n",
    "Y_test = dfytest.values\n",
    "Y_test -= 1\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[0 1 2 3 4 5]\n",
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "print(Y_test)\n",
    "Y_test = le.fit_transform(Y_test)\n",
    "print(le.classes_)\n",
    "Y_test = to_categorical(Y_test, 6)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (7352, 561)\n",
      "Shape of X_test:  (2947, 561)\n",
      "Shape of y_train:  (7352, 6)\n",
      "Shape of y_test (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",Y_train.shape)\n",
    "print(\"Shape of y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a model\n",
    "This time we're going to use QKeras layers.\n",
    "QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models.\n",
    "\n",
    "https://github.com/google/qkeras\n",
    "\n",
    "It is maintained by Google and we recently added support for QKeras model to hls4ml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# clf = MLPClassifier(beta_1=0.5553817511197982, beta_2=0.7408615040451714,\n",
    "#               epsilon=0.769773517554749, hidden_layer_sizes=(64,128,64),\n",
    "#               learning_rate='adaptive', max_iter=150,\n",
    "#               momentum=0.9205475833293032, solver='lbfgs',\n",
    "#               validation_fraction=0.7720568212000914).fit(X_train, Y_train)\n",
    "# clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_bits=1\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(QDense(20, input_shape=(561,), name='fc1', kernel_quantizer=quantized_bits(8,int_bits,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(8,int_bits,alpha=1),\n",
    "#                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ) )\n",
    "# model.add(QActivation(activation=quantized_relu(8,int_bits,use_stochastic_rounding=False), name='relu1'))\n",
    "# model.add(QDense( 64, name='fc2',\n",
    "#                 kernel_quantizer=quantized_bits(8,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,int_bits,alpha=1),\n",
    "#                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "# model.add(QActivation(activation=quantized_relu(8,int_bits,use_stochastic_rounding=False), name='relu2'))\n",
    "# model.add(QDense(64 ,name='fc3',\n",
    "#                 kernel_quantizer=quantized_bits(8,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,int_bits,alpha=1),\n",
    "#                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "# model.add(QActivation(activation=quantized_relu(8,int_bits,use_stochastic_rounding=False), name='relu3'))\n",
    "# model.add(QDense( 6, name='output',\n",
    "#                 kernel_quantizer=quantized_bits(8,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,int_bits,alpha=1),\n",
    "#                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "# model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from callbacks import all_callbacks\n",
    "# adam = Adam(lr=0.01)\n",
    "# model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "# callbacks= all_callbacks( outputDir = 'HAR_test')\n",
    "# #callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "# model.fit(X_train, Y_train, batch_size=128,\n",
    "#               epochs=100,validation_split=0.2, verbose=1, shuffle=True,\n",
    "#               callbacks = callbacks.callbacks);\n",
    "# model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "# model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "# model.evaluate(X_test,Y_test)\n",
    "# model.save(\"HAR_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 00:04:08.247848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"HAR_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.9433\n",
      " ACCURACY IS 0.9433321952819824\n"
     ]
    }
   ],
   "source": [
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=561\n",
    "layer_2=20\n",
    "layer_3=64\n",
    "layer_4=64\n",
    "layer_5=6\n",
    "int_bits=1\n",
    "sign_bit=1\n",
    "bits=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "we=model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.078125, -0.03125 ,  0.09375 , ..., -0.015625,  0.03125 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       ...,\n",
       "       [ 0.015625, -0.09375 , -0.15625 , ...,  0.03125 ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.03125 ,  0.234375,  0.015625, ..., -0.046875,  0.015625,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.09375 ,  0.046875, ...,  0.      ,  0.046875,\n",
       "         0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of inputs with only zeros=  0\n"
     ]
    }
   ],
   "source": [
    "num_inp=np.sum(we==0,axis=1)\n",
    "total_zero_weights = np.sum(num_inp)\n",
    "num_inputs_with_zero_weights=np.where(num_inp == we.shape[1])[0]\n",
    "num_inputs = len(num_inputs_with_zero_weights)\n",
    "print(\"Num of inputs with only zeros= \",num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import estimate as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'estimate' from '/home/edge/Desktop/argykokk/hls4ml-tutorial/networks/HAR/estimate.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=2\n",
    "reuse=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero weight are:  4381\n",
      "non-zero weight are:  6839\n",
      "Mul ins = 33 and Max muls = 69 and Saved muls = 0 Reuse factor = 100\n",
      "Muxes LUTS: 0\n",
      "DSPs: 33\n",
      "LUT cost2= 33170 bias acc= 280 mult acc95466\n",
      "LUTs prediction: 128916\n",
      "Initial muls: 11220 Real muls: 6839 Initial neurons: 20 Tuned neurons: 12\n",
      "FFs prediction: 131000\n",
      "zero weight are:  472\n",
      "non-zero weight are:  808\n",
      "Mul ins = 156 and Max muls = 9 and Saved muls = 147 Reuse factor = 100\n",
      "Muxes LUTS: 1911\n",
      "DSPs: 9\n",
      "LUT cost2= 4712 bias acc= 896 mult acc10416\n",
      "LUTs prediction: 16024\n",
      "Initial muls: 1280 Real muls: 808 Initial neurons: 64 Tuned neurons: 40\n",
      "FFs prediction: 15336\n",
      "zero weight are:  2130\n",
      "non-zero weight are:  1966\n",
      "Mul ins = 129 and Max muls = 20 and Saved muls = 109 Reuse factor = 100\n",
      "Muxes LUTS: 1417\n",
      "DSPs: 20\n",
      "LUT cost2= 10930 bias acc= 896 mult acc26628\n",
      "LUTs prediction: 38454\n",
      "Initial muls: 4096 Real muls: 1966 Initial neurons: 64 Tuned neurons: 30\n",
      "FFs prediction: 36379\n",
      "zero weight are:  86\n",
      "non-zero weight are:  298\n",
      "Mul ins = 89 and Max muls = 3 and Saved muls = 86 Reuse factor = 100\n",
      "Muxes LUTS: 1118\n",
      "DSPs: 3\n",
      "LUT cost2= 2605 bias acc= 84 mult acc4088\n",
      "LUTs prediction: 6777\n",
      "Initial muls: 384 Real muls: 298 Initial neurons: 6 Tuned neurons: 4\n",
      "FFs prediction: 6056\n",
      "CPU times: user 105 ms, sys: 423 µs, total: 105 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#input_num, neurons_num, layer_id, model\n",
    "luts, ffs = es.estimate(561,20,0,model,reuse,param)\n",
    "luts, ffs = es.estimate(20,64,2,model,reuse,param)\n",
    "luts, ffs = es.estimate(64,64,4,model,reuse,param)\n",
    "luts, ffs = es.estimate(64,6,6,model,reuse,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='HAR/hls4ml_prj', part='xc7z007s-clg225-2'\n",
    ")\n",
    "hls_model.compile()\n",
    "\n",
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
