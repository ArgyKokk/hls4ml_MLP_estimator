{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 03:29:43.293583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-22 03:29:43.388232: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the cardio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2126, 22)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset.csv', sep = ';')\n",
    "print (np.shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=np.argmax(Y_test,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (1488, 21)\n",
      "Shape of X_test:  (638, 21)\n",
      "Shape of y_train:  (1488, 3)\n",
      "Shape of y_test (638, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",Y_train.shape)\n",
    "print(\"Shape of y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 2**4\n",
    "sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# for i in range(0,len(X_train)):\n",
    "#    X_train[i] = [int(x*norm)/norm for x in X_train[i]]\n",
    "# for i in range(0,len(X_test)):\n",
    "#    X_test[i] = [int(x*norm)/norm for x in X_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import load\n",
    "loaded_model = load('./Cardio.MLP_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8887147335423198"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = MLPClassifier(beta_1=0.004044058262057914, beta_2=0.2692099545241596,\n",
    "              epsilon=0.4100816459563625, hidden_layer_sizes=3, max_iter=150,\n",
    "              momentum=0.8221177331942455, nesterovs_momentum=False,\n",
    "              solver='lbfgs', validation_fraction=0.511318982546456,alpha=0.0001).fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=loaded_model.coefs_[0]\n",
    "b1=loaded_model.intercepts_[0]\n",
    "w2=loaded_model.coefs_[1]\n",
    "b2=loaded_model.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu,quantized_po2\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(QDense(3, input_shape=(21,), name='fc1', kernel_quantizer=quantized_bits(8,0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(8,0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(8,0,use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(3, name='output',\n",
    "                kernel_quantizer=quantized_bits(8,0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "model.layers[0].set_weights(wb1)\n",
    "model.layers[2].set_weights(wb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1190/1190 [==============================] - 4s 3ms/step - loss: 0.4239 - accuracy: 0.8412 - val_loss: 0.3521 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "1190/1190 [==============================] - 3s 2ms/step - loss: 0.3961 - accuracy: 0.8546 - val_loss: 0.3442 - val_accuracy: 0.8792 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "1190/1190 [==============================] - 3s 3ms/step - loss: 0.3860 - accuracy: 0.8580 - val_loss: 0.3379 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "1190/1190 [==============================] - 3s 2ms/step - loss: 0.3793 - accuracy: 0.8580 - val_loss: 0.3367 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "1190/1190 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8555 - val_loss: 0.3290 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fc1': {'weights': [array([[-0.34375  ,  0.8671875, -0.09375  ],\n",
       "          [ 0.9921875, -1.       , -0.859375 ],\n",
       "          [-0.265625 ,  0.75     ,  0.203125 ],\n",
       "          [ 0.9921875, -0.734375 ,  0.40625  ],\n",
       "          [ 0.40625  ,  0.1015625,  0.28125  ],\n",
       "          [-0.203125 ,  0.1328125,  0.1484375],\n",
       "          [-0.984375 ,  0.9765625,  0.9765625],\n",
       "          [-0.7578125,  0.8125   ,  0.5      ],\n",
       "          [ 0.3671875, -0.703125 ,  0.671875 ],\n",
       "          [-0.6875   ,  0.9140625, -0.671875 ],\n",
       "          [ 0.7109375, -0.1640625, -0.09375  ],\n",
       "          [ 0.2890625,  0.1875   , -0.015625 ],\n",
       "          [ 0.1171875, -0.234375 , -0.453125 ],\n",
       "          [-0.0546875,  0.296875 ,  0.0625   ],\n",
       "          [-0.03125  , -0.1640625,  0.0390625],\n",
       "          [ 0.03125  , -0.1640625,  0.375    ],\n",
       "          [ 0.171875 , -0.1171875, -0.5390625],\n",
       "          [ 0.4296875,  0.0078125, -0.53125  ],\n",
       "          [ 0.       ,  0.046875 , -0.96875  ],\n",
       "          [-0.984375 ,  0.671875 ,  0.96875  ],\n",
       "          [ 0.0234375, -0.359375 , -0.3671875]], dtype=float32),\n",
       "   array([ 0.375    , -0.0078125,  0.46875  ], dtype=float32)]},\n",
       " 'output': {'weights': [array([[ 0.9921875, -0.9921875, -1.       ],\n",
       "          [-1.       ,  0.9921875,  0.953125 ],\n",
       "          [-0.984375 , -1.       ,  0.9921875]], dtype=float32),\n",
       "   array([ 0.9140625, -0.3671875, -1.       ], dtype=float32)]}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = Adam(lr=0.003)\n",
    "\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "callbacks= all_callbacks( outputDir = 'cardio_classification_prune')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=1,\n",
    "          epochs=5,validation_split=0.2, verbose=1, shuffle=True,\n",
    "          callbacks = callbacks.callbacks);\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CARDIO_MODEL/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CARDIO_MODEL/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "model.save(\"CARDIO_MODEL\")\n",
    "#model = tf.keras.models.load_model(\"CARDIO_MODEL\")\n",
    "accuracy=model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'estimate' from '/home/edge/Desktop/argykokk/hls4ml-tutorial/networks/cardio/estimate.py'>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import estimate as es\n",
    "from importlib import reload\n",
    "reload(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=2\n",
    "reuse=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mul ins = 32 and Max muls = 1 and Saved muls = 31 Reuse factor = 100\n",
      "Muxes LUTS: 403\n",
      "DSPs: 1\n",
      "LUT cost2= 377 bias acc= 42 mult acc826\n",
      "LUTs prediction: 1245\n",
      "Initial muls: 63 Real muls: 62 Initial neurons: 3 Tuned neurons: 3\n",
      "FFs prediction: 1959\n",
      "Mul ins = 1 and Max muls = 1 and Saved muls = 0 Reuse factor = 100\n",
      "Muxes LUTS: 0\n",
      "DSPs: 1\n",
      "LUT cost2= 128 bias acc= 42 mult acc84\n",
      "LUTs prediction: 254\n",
      "Initial muls: 9 Real muls: 9 Initial neurons: 3 Tuned neurons: 3\n",
      "FFs prediction: 771\n",
      "CPU times: user 12.5 ms, sys: 67 Âµs, total: 12.6 ms\n",
      "Wall time: 11.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/edge/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#input_num, neurons_num, layer_id, model\n",
    "luts, ffs = es.estimate(21,3,0,model,reuse,param)\n",
    "luts, ffs = es.estimate(3,3,2,model,reuse,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 21]], output shape: [None, 21]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 21]], output shape: [None, 3]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  fc1_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  fc1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,1>\n",
      "      bias:          fixed<8,1>\n",
      "      accum:         fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  fc1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      table:         fixed<18,8>\n",
      "    ReuseFactor:     1\n",
      "    TableSize:       1024\n",
      "  relu1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,0,RND_CONV,SAT>\n",
      "      table:         fixed<18,8>\n",
      "    ReuseFactor:     1\n",
      "    TableSize:       1024\n",
      "  output\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,1>\n",
      "      bias:          fixed<8,1>\n",
      "      accum:         fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  output_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      table:         fixed<18,8>\n",
      "    ReuseFactor:     1\n",
      "    TableSize:       1024\n",
      "  softmax\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      table:         fixed<18,8>\n",
      "      exp_table:     fixed<18,8,RND,SAT>\n",
      "      inv_table:     fixed<18,8,RND,SAT>\n",
      "    ReuseFactor:     1\n",
      "    TableSize:       1024\n",
      "    Implementation:  stable\n",
      "    Skip:            False\n",
      "    exp_table_t:     ap_fixed<18,8>\n",
      "    inv_table_t:     ap_fixed<18,4>\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 21]], output shape: [None, 21]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 21]], output shape: [None, 3]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n",
      "20/20 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='CARDIO/hls4ml_prj', part='xc7z007s-clg225-2'\n",
    ")\n",
    "hls_model.compile()\n",
    "\n",
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
